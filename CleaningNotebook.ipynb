{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================================================================================================\n",
    "# USER INPUT!\n",
    "# Here I specify which data files need reading in\n",
    "datafilenames = [\"train.csv\"] # In this case I only have one file to read in\n",
    "#================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldataframes = [pd.read_csv(filename) for filename in datafilenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here are a bunch of functions that are aimed at detecting dirty data and cleaning it\n",
    "\n",
    "# This function takes a column and does a tally of the different types of entries (int, float, string, etc.)\n",
    "# It then spits out a tuple of the different types and their relative frequencies in the column\n",
    "def ratiosOfDifferentTypes(column):\n",
    "    uniquerows = column.drop_duplicates() #.dropna().drop_duplicates() THIS SHOULD BE FIXED!!! WE NEED TO ALSO DO .dropna() !!!\n",
    "    uniquerows = uniquerows.sample(n=min(1000,uniquerows.size))\n",
    "    types = [type(entry) for entry in uniquerows]\n",
    "    differenttypes = list(set(types))\n",
    "    tally = [types.count(giventype) for giventype in differenttypes]\n",
    "    total = sum(tally)*1.\n",
    "    frequencies = [tallyelement / total for tallyelement in tally]\n",
    "    return (differenttypes,frequencies)\n",
    "\n",
    "# This function takes a column and decides which type its entries are meant to be like.\n",
    "# It returns the type. If the entries are so mixed that it can't decide, it returns object.\n",
    "def decideType(column):\n",
    "    typesandratios = ratiosOfDifferentTypes(column)\n",
    "    if max(typesandratios[1]) >= 0.8:\n",
    "        # all the rows should probably be of the same type and some have been inputted incorrectly\n",
    "        correcttype = typesandratios[0][typesandratios[1].index(max(typesandratios[1]))]\n",
    "    else:\n",
    "        # the rows have a very mixed type and it's not very clear what the correct type is\n",
    "        correcttype = object\n",
    "    return correcttype\n",
    "\n",
    "# This function goes through all columns in the dataframe and returns the name of the columns that are dirty,\n",
    "# i.e. that have mixed types of entries.\n",
    "def findMixedTypes(dataframe):\n",
    "    return [col for col in dataframe if len(ratiosOfDifferentTypes(dataframe[col])[1])>1]\n",
    "\n",
    "# This function takes a dataframe and for each column says whether it's clean or dirty. If it's dirty,\n",
    "# it tries to decide which type it should be.\n",
    "def analyzeColumnTypes(dataframe):\n",
    "    mixedtypecolumns = findMixedTypes(dataframe)\n",
    "    if mixedtypecolumns==[]:\n",
    "        print \"All columns have a single type; they are 'clean'. (They may be incorrect though, or have NaNs).\"\n",
    "    else:\n",
    "        print \"The columns\",mixedtypecolumns,\"have mixed types:\\n\"\n",
    "        correcttypes = [(colname,decideType(dataframe[colname])) for colname in mixedtypecolumns]\n",
    "        for typ in correcttypes:\n",
    "            if typ[1]==object:\n",
    "                print \" - \\'\" + typ[0] + \"\\'\" + \" is so mixed it's hard to tell the right type\"\n",
    "            else:\n",
    "                print \" - \\'\" + typ[0] + \"\\'\" + \" should be \" + \"\\'\" + typ[1].__name__ + \"\\'\"\n",
    "        print \"\\nAll other columns have a single type; they are 'clean'. (They may be incorrect though, or have NaNs).\"\n",
    "    return mixedtypecolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING DATAFRAME FROM train.csv:\n",
      "----------------------------------------------------\n",
      "The columns ['Cabin', 'Embarked'] have mixed types:\n",
      "\n",
      " - 'Cabin' should be 'str'\n",
      " - 'Embarked' is so mixed it's hard to tell the right type\n",
      "\n",
      "All other columns have a single type; they are 'clean'. (They may be incorrect though, or have NaNs).\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mixedtypesindataframes = range(len(alldataframes))\n",
    "for ii in range(len(alldataframes)):\n",
    "    print \"ANALYZING DATAFRAME FROM \" + datafilenames[ii] + \":\"\n",
    "    print \"----------------------------------------------------\"\n",
    "    mixedtypesindataframes[ii] =  analyzeColumnTypes(alldataframes[ii])\n",
    "    print \"----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALYZING DATAFRAME FROM train.csv:\n",
      "----------------------------------------------------\n",
      "Column 'Cabin' has the following unique entries:\n",
      "\n",
      "[nan 'A10' 'A14' 'A16' 'A19' 'A20' 'A23' 'A24' 'A26' 'A31' 'A32' 'A34'\n",
      " 'A36' 'A5' 'A6' 'A7' 'B101' 'B102' 'B18' 'B19' 'B20' 'B22' 'B28' 'B3'\n",
      " 'B30' 'B35' 'B37' 'B38' 'B39' 'B4' 'B41' 'B42' 'B49' 'B5' 'B50'\n",
      " 'B51 B53 B55' 'B57 B59 B63 B66' 'B58 B60' 'B69' 'B71' 'B73' 'B77' 'B78'\n",
      " 'B79' 'B80' 'B82 B84' 'B86' 'B94' 'B96 B98' 'C101' 'C103' 'C104' 'C106'\n",
      " 'C110' 'C111' 'C118' 'C123' 'C124' 'C125' 'C126' 'C128' 'C148' 'C2'\n",
      " 'C22 C26' 'C23 C25 C27' 'C30' 'C32' 'C45' 'C46' 'C47' 'C49' 'C50' 'C52'\n",
      " 'C54' 'C62 C64' 'C65' 'C68' 'C7' 'C70' 'C78' 'C82' 'C83' 'C85' 'C86' 'C87'\n",
      " 'C90' 'C91' 'C92' 'C93' 'C95' 'C99' 'D' 'D10 D12' 'D11' 'D15' 'D17' 'D19'\n",
      " 'D20' 'D21' 'D26' 'D28' 'D30' 'D33' 'D35' 'D36' 'D37' 'D45' 'D46' 'D47'\n",
      " 'D48' 'D49' 'D50' 'D56' 'D6' 'D7' 'D9' 'E10' 'E101' 'E12' 'E121' 'E17'\n",
      " 'E24' 'E25' 'E31' 'E33' 'E34' 'E36' 'E38' 'E40' 'E44' 'E46' 'E49' 'E50'\n",
      " 'E58' 'E63' 'E67' 'E68' 'E77' 'E8' 'F E69' 'F G63' 'F G73' 'F2' 'F33'\n",
      " 'F38' 'F4' 'G6' 'T']\n",
      "\n",
      "Column 'Embarked' has the following unique entries:\n",
      "\n",
      "[nan 'C' 'Q' 'S']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ii in range(len(alldataframes)):\n",
    "    print \"ANALYZING DATAFRAME FROM \" + datafilenames[ii] + \":\"\n",
    "    print \"----------------------------------------------------\"\n",
    "    for col in mixedtypesindataframes[ii]:\n",
    "        print \"Column '\" + col + \"' has the following unique entries:\\n\"\n",
    "        print np.sort(alldataframes[ii][col].unique())\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#================================================================================================\n",
    "# USER INPUT!\n",
    "# After having run the previous cells you know which columns are clean and dirty.\n",
    "# Look at the unique values of the dirty ones, given above. Use this information to clean them up\n",
    "\n",
    "# In each dataframe, there are certain dirty columns that should be numeric\n",
    "columnsthatshouldbenumeric = [\n",
    "    [\"Survived\",\"Pclass\"]\n",
    "]\n",
    "# In each column there will be some conventions on how the bad things are written out.\n",
    "# For each column that should be numeric, we specify a tuple with the info\n",
    "# (decimaldelimiter (a string),thousanddelimeter (a string), listofstringstoremove (a list))\n",
    "structureofeachcolumn = [\n",
    "    [\n",
    "        (\".\",\",\",[\"-\",\" \",\"%\"]),\n",
    "        (\".\",\",\",[\"-\",\" \"])\n",
    "    ]\n",
    "]\n",
    "\n",
    "columnsthatshouldbestrings = [\n",
    "    [\"Name\",\"Sex\"]\n",
    "]\n",
    "\n",
    "columnsthatshouldbedatetimes = [\n",
    "    []\n",
    "]\n",
    "#================================================================================================\n",
    "\n",
    "# FROM HERE ON IT'S AUTOMATIC\n",
    "\n",
    "# This is a test column to see if it all works. CAN BE REMOVED.\n",
    "# messedupcolumn = pd.Series([1,\"200\",3,4,5.99,11,\"11 , 000 .203\",\"11-2%22\"])\n",
    "\n",
    "# This function takes a column that should be numeric but is all dirty with badly made strings. It removes\n",
    "# the thousand-delimiters, it replaces the decimaldelimiters with periods, and removes any user-chosen \n",
    "# additional set of characters\n",
    "def turnToNumeric(column,decimaldelimiter=\".\",thousanddelimeter=\",\",listofstringstoremove=[\"-\",\" \",\"%\"]):\n",
    "    toremoveregex = str(listofstringstoremove + [thousanddelimeter]).rstrip(\"]'\").lstrip(\"'[\").replace(\"', '\",\"|\")\n",
    "    numericcolumn = pd.to_numeric(column.astype(str).str.replace(toremoveregex,\"\").str.replace(decimaldelimiter,\".\"))\n",
    "    return numericcolumn\n",
    "\n",
    "# This function takes a dirty column that should all be strings and turns it into such\n",
    "def turnToString(column):\n",
    "    return column.astype(str)\n",
    "\n",
    "def turnToDate(column):\n",
    "    return pd.to_datetime(column,dayfirst=True)\n",
    "\n",
    "for ii in range(len(alldataframes)):\n",
    "    for (jj,coltofix) in enumerate(columnsthatshouldbestrings[ii]):\n",
    "        alldataframes[ii].loc[:,coltofix] = turnToString(alldataframes[ii][coltofix])\n",
    "    \n",
    "    for (jj,coltofix) in enumerate(columnsthatshouldbedatetimes[ii]):\n",
    "        alldataframes[ii].loc[:,coltofix] = turnToDate(alldataframes[ii][coltofix])\n",
    "        \n",
    "    for (jj,coltofix) in enumerate(columnsthatshouldbenumeric[ii]):\n",
    "        alldataframes[ii].loc[:,coltofix] = turnToNumeric(alldataframes[ii][coltofix],\n",
    "                                                    structureofeachcolumn[ii][jj][0],\n",
    "                                                    structureofeachcolumn[ii][jj][1],\n",
    "                                                    structureofeachcolumn[ii][jj][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#================================================================================================\n",
    "# USER INPUT!\n",
    "# Now we need to remove those rows of data that are missing critical information, i.e. remove \n",
    "# those rows that have a NaN for something very important.\n",
    "criticalcolumns = [\n",
    "    [\"Survived\",\"Pclass\"]\n",
    "]\n",
    "#================================================================================================\n",
    "\n",
    "# FROM HERE ON IT'S AUTOMATIC\n",
    "\n",
    "for ii in range(len(alldataframes)):\n",
    "    alldataframes[ii] = alldataframes[ii].dropna(subset = criticalcolumns[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldataframes[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
